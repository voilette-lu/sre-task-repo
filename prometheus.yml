serverFiles:
# Insert the correct values in all parameters marked with "#TODO"
  alerting_rules.yml:
      groups:
      - name: NodeDown
        rules:
        # Alert for any instance that is unreachable for >5 minutes.
        # default lookback window for prometheus is set to 5min.
        # Thank you for your observation. The trigger duration specified in the Prometheus alert configuration refers to the duration for which the alert condition must be continuously true before triggering the alert. In this case, the trigger duration of 2 minutes means that the condition up{job="kubernetes-nodes"} == 0 (indicating that no nodes are up) must persist for at least an extra 2 minutes before the alert is triggered. If you remember, in class last Tuesday, Salim explained the concept of trigger duration (you could watch the recording for a refresher). Salim explained that as SREs, you do not want an alert just firing once a certain threshold is reached. You want to be sure that the situation persists before the alerts fire. So in this case, we just want to ascertain that the instance has been down for at least five minutes, and the 2 minutes trigger duration is just for good measure to prevent toil, especially as auto-scaling/self-healing has been configured in our cluster setup. But if you want to attend to the problem without a further waiting, then you can change the trigger duration to maybe 0 minutes or just a few seconds.
        - alert: InstanceDown
          expr: up{job="kubernetes-nodes"} == 0
          for: 2m
          labels:
            severity: page
          annotations:
            host: "{{ $labels.kubernetes_io_hostname }}"
            summary: "Instance down"
            description: "Node {{ $labels.kubernetes_io_hostname }} has been down for more than 5 minutes."
      - name: low_memory_alert
        rules:
        - alert: LowMemory
          expr: (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 < 85
          for: 2m
          labels:
            severity: warning
          annotations:
            host: "{{ $labels.kubernetes_node }}"
            summary: "{{ $labels.kubernetes_node }} Host is low on memory. Only {{ $value }}% left"
            description: "{{ $labels.kubernetes_node }} node is low on memory. Only {{ $value }}% left"
        - alert: KubePersistentVolumeErrors
          expr: kube_persistentvolume_status_phase{job="kubernetes-service-endpoints",phase=~"Failed|Pending"} > 0
          for: 2m
          labels:
            severity: critical
          annotations:
            description: The persistent volume {{ $labels.persistentvolume }} has status {{ $labels.phase }}
            summary: PersistentVolume is having issues with provisioning.
        - alert: KubePodCrashLooping
          expr: rate(kube_pod_container_status_restarts_total{job="kubernetes-service-endpoints",namespace=~".*"}[5m]) * 60 * 5 > 0
          for: 2m
          labels:
            severity: warning
          annotations:
            description: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is restarting {{ printf "%.2f" $value }} times / 5 minutes.
            summary: Pod is crash looping.
        - alert: KubePodNotReady
          expr: sum by(namespace, pod) (max by(namespace, pod) (kube_pod_status_phase{job="kubernetes-service-endpoints",namespace=~".*",phase=~"Pending|Unknown"}) * on(namespace, pod)    group_left(owner_kind) topk by(namespace, pod) (1, max by(namespace, pod, owner_kind) (kube_pod_owner{owner_kind!="Job"}))) > 0
          for: 2m
          labels:
            severity: warning
          annotations:
            description: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 5 minutes.
            summary: Pod has been in a non-ready state for more than 2 minutes.